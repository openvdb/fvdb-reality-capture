{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b8bc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fvdb_reality_capture as frc\n",
    "import logging\n",
    "import cv2\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Let's use verbose logging to track what happens.\n",
    "# For less output, set level=logging.WARN, for more set level=logging.DEBUG\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f41ef11",
   "metadata": {},
   "source": [
    "## Download some example data\n",
    "First, let's download some example data to run on. These datasets are the output of a COLMAP SfM pipeline on a sequence of images.\n",
    "They contain images, camera poses (camera to world transformations), and camera projection parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75912c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download example data for running splats on\n",
    "frc.tools.download_example_data(dataset=\"all\", download_path=\"./data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e111f2f5",
   "metadata": {},
   "source": [
    "# Manipulating Structure-from-Motion Data\n",
    "The `fvdb_reality_capture` library provides a number of tools for working with Structure-from-Motion (SfM) data.\n",
    "The basic in-memory representation of an SfmDataset is the `fvdb_reality_capture.SfmScene` class. \n",
    "Note that this class does not load all images and masks into memory since this can quickly\n",
    "use up all available RAM. Instead it stores paths to images and masks, and leverages a filesystem\n",
    "cache for ephemeral quantities derived from the dataset (e.g. downsampled images, or masks\n",
    "computed by cropping a scene). When you load a dataset from disk, it will return both the\n",
    "`SfmScene` for that dataset as well as it's cache represented as an `fvdb_reality_capture.Cache` object.\n",
    "\n",
    "An `SfmScene` consists of a few main components:\n",
    " 1. `SfmScene.cameras`: Information about the camera(s) used to capture the scene. \n",
    "   - This is represented as a dictionary mapping unique integer camera IDs to `SfmCameraMetadata` objects. The `SfmCameraMetadata` class contains the camera intrinsics (projection parameters, distortion parameters, camera type, etc). *NOTE: The number of cameras is not the same as the number of images. If you used a drone with 3 mounted cameras to capture a scene, then `len(SfmScene.cameras)` will be 3.*\n",
    " 2. `SfmScene.images`: Information about each captured image and its pose in the scene. \n",
    "  - This is represented as a python list of `SfmCameraMetadata` objects each of which contains the camera-to-world transform (and its inverse), the filesystem path to the image and mask (if present), the SfM correspondence points visible from this image, as well as the `SfmCameraMetada` reprenting the camera that captured this image.\n",
    " 3. `SfmScene.points`/`SfmScene.points_rgb`/`SfmScene.points_err`: Information about the 3D correspondence points reconstructed \n",
    " by the SfM algorithm. \n",
    "  - These are represented as NumPy arrays with shapes `(N,3)`/`(N,3)`/`(N,)` (where `N` is the number of points) and encode the point positions, RGB colors (as uint8 from 0 - 255), and (unnormalized) confidence scores on the accuracy of each point.\n",
    " 4. `SfmScene.transformation_matrix`: \n",
    "  - A 4x4 transformation matrix represented as a NumPy array encoding a mapping from some canonical coordinate space to scene coordinates. By default, this will be the Idendity matrix, but it can change when you transform the scene (e.g. to normalize it).\n",
    " 5. `SfmScene.scene_bbox`: A bounding box which is guaranteed to contain all the `SfmScene.points` points in the scene. \n",
    "  - This is represented as a NumPy array of shape `(6,)` of the form `(bmin_x, bmin_y, bmin_z, bmax_x, bmax_y, bmax_z)`. By default `bmin_x=bmin_y=bmin_z=-inf` and `bmax_x=bmax_y=bmax_z=inf` but this can change when you transform the scene (e.g. by cropping it).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4031aba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"./data/360_v2/garden\"\n",
    "scene = frc.io.load_colmap_scene(pathlib.Path(dataset_path))\n",
    "\n",
    "# Visualize an image in an SfmScene and the 3D points visible from that images\n",
    "# projected onto the image plane as blue dots.\n",
    "def plot_image_from_scene(scene: frc.sfm_scene.SfmScene, image_id: int):\n",
    "    image_meta: frc.sfm_scene.SfmImageMetadata = scene.images[image_id]\n",
    "    camera_meta: frc.sfm_scene.SfmCameraMetadata = image_meta.camera_metadata\n",
    "\n",
    "    # Get the visible 3d points for this image\n",
    "    visible_points_3d: np.ndarray = scene.points[image_meta.point_indices]\n",
    "\n",
    "    # Project those points onto the image plane\n",
    "    # 1. Get the world -> camera space transform and projection matrix\n",
    "    world_to_cam_matrix: np.ndarray = image_meta.world_to_camera_matrix\n",
    "    projection_matrix: np.ndarray = camera_meta.projection_matrix\n",
    "    # 2. Transform world points to camera space\n",
    "    visible_points_3d_cam_space = world_to_cam_matrix[:3,:3] @ visible_points_3d.T + world_to_cam_matrix[:3,3:4]\n",
    "    # 3. Transform camera space coordinates to image space\n",
    "    visible_points_2d = projection_matrix @ visible_points_3d_cam_space\n",
    "    visible_points_2d /= visible_points_2d[2]\n",
    "\n",
    "    # Load the image and convert to RGB (OpenCV uses BGR by default)\n",
    "    loaded_image = cv2.imread(image_meta.image_path)\n",
    "    assert loaded_image is not None, f\"Failed to load image at {image_meta.image_path}\"\n",
    "    loaded_image = cv2.cvtColor(loaded_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Plot the image and projected points\n",
    "    plt.title(f\"SfmScene Image {image_id}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(loaded_image)\n",
    "    plt.scatter(visible_points_2d[0], visible_points_2d[1], color=\"#432de9\", marker=\".\", s=2)\n",
    "\n",
    "# Plot three images and points alongside each other\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plot_image_from_scene(scene, 8)\n",
    "plt.subplot(1, 3, 2)\n",
    "plot_image_from_scene(scene, 16)\n",
    "plt.subplot(1, 3, 3)\n",
    "plot_image_from_scene(scene, 32)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c00950",
   "metadata": {},
   "source": [
    "## Optimizing a Gaussian Splat Scene from Data\n",
    "The `fvdb_reality_capture` module provides a set of easy-to-use tools for optimizing a Gaussian Splat scene from\n",
    "data. The simplest way to get started is by creating a `SceneOptimizer` and calling train.\n",
    "This will produce a trained model which can be evaluated, saved, or used for downstream tasks (like meshing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70d9390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have data, let's optimize a 3d Gaussian Splat scene on that data\n",
    "# This creates a new optimizer for your dataset with default parameters which should produce\n",
    "# reasonable results on the vast majority of inputs\n",
    "\n",
    "# TODO:\n",
    "#  - Set arguments to use every image in training by default\n",
    "#  - In this example, use a validation set to show how to do this\n",
    "#  - Viewer disabled by default, enabling it shows a nice UI in jupyter\n",
    "scene_optimizer = frc.training.SceneOptimizationRunner.new_run(dataset_path=\"./data/360_v2/garden\")\n",
    "scene_optimizer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fvdb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
